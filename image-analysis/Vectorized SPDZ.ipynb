{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from math import log\n",
    "log2 = lambda x: log(x)/log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for arbitrary precision ints\n",
    "\n",
    "DTYPE = 'object'\n",
    "Q = 503928829565480993\n",
    "\n",
    "# we need room for summing MAX_SUM values of MAX_DEGREE before during modulus reduction\n",
    "MAX_DEGREE = 2\n",
    "MAX_SUM = 2**10\n",
    "assert MAX_DEGREE * log2(Q) + log2(MAX_SUM) < 128\n",
    "\n",
    "BASE = 2\n",
    "PRECISION_INTEGRAL   = 10\n",
    "PRECISION_FRACTIONAL = 16\n",
    "# TODO Gap as needed for local truncating\n",
    "\n",
    "# we need room for double precision before truncating\n",
    "assert PRECISION_INTEGRAL + 2 * PRECISION_FRACTIONAL < log(Q)/log(BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for arbitrary precision ints\n",
    "\n",
    "DTYPE = 'object'\n",
    "Q = 2657003489534545107915232808830590043\n",
    "\n",
    "# we need room for summing MAX_SUM values of MAX_DEGREE before during modulus reduction\n",
    "MAX_DEGREE = 2\n",
    "MAX_SUM = 2**12\n",
    "assert MAX_DEGREE * log2(Q) + log2(MAX_SUM) < 256\n",
    "\n",
    "BASE = 2\n",
    "PRECISION_INTEGRAL   = 16\n",
    "PRECISION_FRACTIONAL = 32\n",
    "# TODO Gap as needed for local truncating\n",
    "\n",
    "# we need room for double precision before truncating\n",
    "assert PRECISION_INTEGRAL + 2 * PRECISION_FRACTIONAL < log(Q)/log(BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(rationals):\n",
    "    return (rationals * BASE**PRECISION_FRACTIONAL).astype('int').astype(DTYPE) % Q\n",
    "\n",
    "def decode(elements):\n",
    "    map_negative_range = np.vectorize(lambda element: element if element <= Q/2 else element - Q)\n",
    "    return map_negative_range(elements) / BASE**PRECISION_FRACTIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PublicTensor:\n",
    "    \n",
    "    def __init__(self, values):\n",
    "        self.values = values\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"PublicTensor(%s)\" % decode(self.values)\n",
    "    \n",
    "    def load(values, apply_encoding=True):\n",
    "        if apply_encoding: values = encode(values)\n",
    "        return PublicTensor(values)\n",
    "    \n",
    "    def truncate(self, amount=PRECISION_FRACTIONAL):\n",
    "        truncate = np.vectorize(lambda x: x // BASE**amount if x <= Q/2 else Q - ((Q - x) // BASE**amount))\n",
    "        return PublicTensor(truncate(self.values))\n",
    "    \n",
    "    def add(x, y):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            return PublicTensor((x.values + y.values) % Q)\n",
    "        elif isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.values + y.shares0) % Q\n",
    "            shares1 =             y.shares1\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __add__(x, y):\n",
    "        return x.add(y)\n",
    "        \n",
    "    def sub(x, y):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            return PublicTensor((x.values - y.values) % Q)\n",
    "        elif isinstance(y, PrivateTensor):\n",
    "            # TODO might be more efficient way\n",
    "            shares0 = ((Q-1) * y.shares0 + x.values) % Q\n",
    "            shares1 = ((Q-1) * y.shares1) % Q\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        elif isinstance(y, PublicTensor):\n",
    "            shares0 = (x.shares0 - y.values) % Q\n",
    "            shares1 =  x.shares1\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __sub__(x, y):\n",
    "        return x.sub(y)\n",
    "        \n",
    "    def mul(x, y, truncate=True):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            values = (x.values * y.values) % Q\n",
    "            z = PublicTensor(values)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.values * y.shares0) % Q\n",
    "            shares1 = (x.values * y.shares1) % Q\n",
    "            z = PrivateTensor(shares0, shares1)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "    \n",
    "    def __mul__(x, y):\n",
    "        return x.mul(y)\n",
    "    \n",
    "    def dot(x, y, truncate=True):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            z = PublicTensor(x.values.dot(y.values) % Q)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, PrivateTensor):\n",
    "            shares0 = x.values.dot(y.shares0) % Q\n",
    "            shares1 = x.values.dot(y.shares1) % Q\n",
    "            z = PrivateTensor(shares0, shares1)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def transpose(self):\n",
    "        return PublicTensor(self.values.T)\n",
    "    \n",
    "    def sum0(self):\n",
    "        values = self.values.sum(axis=0, keepdims=True)\n",
    "        return PublicTensor(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PublicTensor([[-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 2.]])\n",
      "PublicTensor([[ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]])\n",
      "PublicTensor([[  4.]\n",
      " [  6.]\n",
      " [  8.]\n",
      " [ 10.]])\n",
      "PublicTensor([[ -5.]\n",
      " [  0.]\n",
      " [  7.]\n",
      " [ 16.]])\n",
      "PublicTensor([[ -5.  -6.  -7.  -8.]\n",
      " [  0.   0.   0.   0.]\n",
      " [  5.   6.   7.   8.]\n",
      " [ 10.  12.  14.  16.]])\n",
      "PublicTensor([[ 10.  12.  14.  16.]])\n"
     ]
    }
   ],
   "source": [
    "x = PublicTensor.load(np.array([1,2,3,4]).reshape(4,1) - 2); print(x)\n",
    "y = PublicTensor.load(np.array([5,6,7,8]).reshape(4,1)); print(y)\n",
    "z = x + y; print(z)\n",
    "z = (x * y); print(z)\n",
    "z = x.dot(y.transpose()); print(z)\n",
    "z = z.sum0(); print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mul_triple(shape):\n",
    "    a = np.array([ random.randrange(Q) for _ in range(np.prod(shape)) ]).astype(DTYPE).reshape(shape)\n",
    "    b = np.array([ random.randrange(Q) for _ in range(np.prod(shape)) ]).astype(DTYPE).reshape(shape)\n",
    "    ab = (a * b) % Q\n",
    "    return PrivateTensor.load(a, False), \\\n",
    "           PrivateTensor.load(b, False), \\\n",
    "           PrivateTensor.load(ab, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dot_triple(m, n, o):\n",
    "    a = np.array([ random.randrange(Q) for _ in range(m*n) ]).astype(DTYPE).reshape((m,n))\n",
    "    b = np.array([ random.randrange(Q) for _ in range(n*o) ]).astype(DTYPE).reshape((n,o))\n",
    "    ab = np.dot(a, b)\n",
    "    return PrivateTensor.load(a, False), \\\n",
    "           PrivateTensor.load(b, False), \\\n",
    "           PrivateTensor.load(ab, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrivateTensor:\n",
    "    \n",
    "    def __init__(self, shares0, shares1):\n",
    "        self.shares0 = shares0\n",
    "        self.shares1 = shares1\n",
    "\n",
    "    def load(values, apply_encoding=True):\n",
    "        if apply_encoding: values = encode(values)\n",
    "        shares0 = np.array([ random.randrange(Q) for _ in range(values.size) ]).astype(DTYPE).reshape(values.shape)\n",
    "        shares1 = (values - shares0) % Q\n",
    "        return PrivateTensor(shares0, shares1)\n",
    "\n",
    "    def reveal(self):\n",
    "        values = (self.shares0 + self.shares1) % Q\n",
    "        return PublicTensor(values)\n",
    "    \n",
    "    def truncate(self, amount=PRECISION_FRACTIONAL):\n",
    "        shares0 = np.floor_divide(self.shares0, BASE**amount)\n",
    "        shares1 = Q - (np.floor_divide(Q - self.shares1, BASE**amount))\n",
    "        return PrivateTensor(shares0, shares1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"PrivateTensor(%s)\" % decode(self.reveal().values)\n",
    "    \n",
    "    def add(x, y):\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.shares0 + y.shares0) % Q\n",
    "            shares1 = (x.shares1 + y.shares1) % Q\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        elif isinstance(y, PublicTensor):\n",
    "            shares0 = (x.shares0 + y.values) % Q\n",
    "            shares1 =  x.shares1\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return x.add(PublicTensor.load(y))\n",
    "        elif isinstance(y, int) or isinstance(y, float):\n",
    "            return x.add(PublicTensor.load(np.array([y])))\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __add__(x, y):\n",
    "        return x.add(y)\n",
    "    \n",
    "    def sub(x, y):\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.shares0 - y.shares0) % Q\n",
    "            shares1 = (x.shares1 - y.shares1) % Q\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        elif isinstance(y, PublicTensor):\n",
    "            shares0 = (x.shares0 - y.values) % Q\n",
    "            shares1 =  x.shares1\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        elif isinstance(y, int):\n",
    "            y = PublicTensor.load(np.array([y]))\n",
    "            return x.sub(y)\n",
    "        elif isinstance(y, float):\n",
    "            y = PublicTensor.load(np.array([y]))\n",
    "            return x.sub(y)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __sub__(x, y):\n",
    "        return x.sub(y)\n",
    "    \n",
    "    def mul(x, y, truncate=True, precomputed=None):\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            assert x.shares0.shape == x.shares1.shape == y.shares0.shape == y.shares1.shape\n",
    "            if precomputed is None: precomputed = generate_mul_triple(x.shares0.shape)\n",
    "            a, b, ab = precomputed\n",
    "            alpha = (x - a).reveal()\n",
    "            beta  = (y - b).reveal()\n",
    "            z = alpha.mul(beta, truncate=False) + \\\n",
    "                alpha.mul(b, truncate=False) + \\\n",
    "                a.mul(beta, truncate=False) + \\\n",
    "                ab\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, PublicTensor):\n",
    "            shares0 = (x.shares0 * y.values) % Q\n",
    "            shares1 = (x.shares1 * y.values) % Q\n",
    "            z = PrivateTensor(shares0, shares1)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return x.mul(PublicTensor.load(y), truncate, precomputed)\n",
    "        elif isinstance(y, int) or isinstance(y, float):\n",
    "            return x.mul(PublicTensor.load(np.array([y])), truncate, precomputed)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __mul__(x, y):\n",
    "        return x.mul(y)\n",
    "        \n",
    "    def dot(x, y, truncate=True, precomputed=None):\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            assert x.shares0.shape == x.shares1.shape \n",
    "            assert y.shares0.shape == y.shares1.shape\n",
    "            m = x.shares0.shape[0]\n",
    "            n = x.shares0.shape[1]\n",
    "            o = y.shares0.shape[1]\n",
    "            assert n == y.shares0.shape[0]\n",
    "            if precomputed is None: precomputed = generate_dot_triple(m, n, o)\n",
    "            a, b, ab = precomputed\n",
    "            alpha = (x - a).reveal()\n",
    "            beta  = (y - b).reveal()\n",
    "            z = alpha.dot(beta, truncate=False) + \\\n",
    "                alpha.dot(b, truncate=False) + \\\n",
    "                a.dot(beta, truncate=False) + \\\n",
    "                ab\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, PublicTensor):\n",
    "            shares0 = x.shares0.dot(y.values) % Q\n",
    "            shares1 = x.shares1.dot(y.values) % Q\n",
    "            z = PrivateTensor(shares0, shares1)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return x.dot(PublicTensor.load(y))\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def neg(self):\n",
    "        return self.mul(PublicTensor(np.array([Q - 1])), truncate=False)\n",
    "        \n",
    "    def transpose(self):\n",
    "        return PrivateTensor(self.shares0.T, self.shares1.T)\n",
    "    \n",
    "    def sum0(self):\n",
    "        shares0 = self.shares0.sum(axis=0, keepdims=True) % Q\n",
    "        shares1 = self.shares1.sum(axis=0, keepdims=True) % Q\n",
    "        return PrivateTensor(shares0, shares1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrivateTensor([[  4.]\n",
      " [  6.]\n",
      " [  8.]\n",
      " [ 10.]])\n",
      "PrivateTensor([[ -5.]\n",
      " [  0.]\n",
      " [  7.]\n",
      " [ 16.]])\n",
      "PrivateTensor([[ -5.  -6.  -7.  -8.]\n",
      " [  0.   0.   0.   0.]\n",
      " [  5.   6.   7.   8.]\n",
      " [ 10.  12.  14.  16.]])\n",
      "PrivateTensor([[ 10.  12.  14.  16.]])\n"
     ]
    }
   ],
   "source": [
    "x = PrivateTensor.load(np.array([1,2,3,4]).reshape(4,1) - 2)\n",
    "y = PrivateTensor.load(np.array([5,6,7,8]).reshape(4,1))\n",
    "z = x + y; print(z)\n",
    "z = (x * y); print(z)\n",
    "z = x.dot(y.transpose()); print(z)\n",
    "z = z.sum0(); print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyTensor:\n",
    "    \n",
    "    def __init__(self, values):\n",
    "        self.values = values\n",
    "\n",
    "    def load(values):\n",
    "        return NumpyTensor(values)\n",
    "\n",
    "    def reveal(self):\n",
    "        return self.values\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"NumpyTensor(%s)\" % self.values\n",
    "    \n",
    "    def add(x, y):\n",
    "        if isinstance(y, NumpyTensor):\n",
    "            return NumpyTensor(x.values + y.values)\n",
    "        elif isinstance(y, int):\n",
    "            return NumpyTensor(x.values + y)\n",
    "        elif isinstance(y, float):\n",
    "            return NumpyTensor(x.values + y)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return NumpyTensor(x.values + y)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __add__(x, y):\n",
    "        return x.add(y)\n",
    "    \n",
    "    def sub(x, y):\n",
    "        if isinstance(y, NumpyTensor):\n",
    "            return NumpyTensor(x.values - y.values)\n",
    "        elif isinstance(y, int):\n",
    "            return NumpyTensor(x.values - y)\n",
    "        elif isinstance(y, float):\n",
    "            return NumpyTensor(x.values - y)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return NumpyTensor(x.values - y)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __sub__(x, y):\n",
    "        return x.sub(y)\n",
    "    \n",
    "    def mul(x, y):\n",
    "        if isinstance(y, NumpyTensor):\n",
    "            return NumpyTensor(x.values * y.values)\n",
    "        elif isinstance(y, int):\n",
    "            return NumpyTensor(x.values * y)\n",
    "        elif isinstance(y, float):\n",
    "            return NumpyTensor(x.values * y)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return NumpyTensor(x.values * y)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __mul__(x, y):\n",
    "        return x.mul(y)\n",
    "        \n",
    "    def dot(x, y):\n",
    "        if isinstance(y, NumpyTensor):\n",
    "            return NumpyTensor(x.values.dot(y.values))\n",
    "        elif isinstance(y, int):\n",
    "            return NumpyTensor(x.values.dot(y))\n",
    "        elif isinstance(y, float):\n",
    "            return NumpyTensor(x.values.dot(y))\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return NumpyTensor(x.values.dot(y))\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def transpose(self):\n",
    "        return NumpyTensor(self.values.T)\n",
    "    \n",
    "    def neg(self):\n",
    "        return NumpyTensor(0 - self.values)\n",
    "\n",
    "    def sum0(self):\n",
    "        return NumpyTensor(self.values.sum(axis=0, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumpyTensor([[ 4]\n",
      " [ 6]\n",
      " [ 8]\n",
      " [10]])\n",
      "NumpyTensor([[-5]\n",
      " [ 0]\n",
      " [ 7]\n",
      " [16]])\n",
      "NumpyTensor([[-5 -6 -7 -8]\n",
      " [ 0  0  0  0]\n",
      " [ 5  6  7  8]\n",
      " [10 12 14 16]])\n",
      "NumpyTensor([[10 12 14 16]])\n"
     ]
    }
   ],
   "source": [
    "x = NumpyTensor.load(np.array([1,2,3,4]).reshape(4,1) - 2)\n",
    "y = NumpyTensor.load(np.array([5,6,7,8]).reshape(4,1))\n",
    "z = x + y; print(z)\n",
    "z = (x * y); print(z)\n",
    "z = x.dot(y.transpose()); print(z)\n",
    "z = z.sum0(); print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    \n",
    "    def __init__(self, num_nodes, num_features, learning_rate=.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_features = num_features\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def initialize(self):\n",
    "        self.weights = .1 * np.random.randn(self.num_features, self.num_nodes)\n",
    "        self.bias = np.zeros((1, self.num_nodes))\n",
    "        \n",
    "    \n",
    "#     def precompute_forward(self, batch_shape):\n",
    "#         assert batch_shape[1] == self.num_features\n",
    "#         dot_triple = generate_dot_triple(batch_shape[0], self.num_features, self.num_nodes)\n",
    "#         return dot_triple\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x.dot(self.weights) + self.bias\n",
    "        self.cache = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        x = self.cache\n",
    "        # compute gradients for internal parameters and update\n",
    "        d_weights = x.transpose().dot(d_out)\n",
    "        d_bias = d_out.sum0()\n",
    "        self.weights = (d_weights * self.learning_rate).neg() + self.weights\n",
    "        self.bias    =    (d_bias * self.learning_rate).neg() + self.bias\n",
    "        # compute and return external gradient\n",
    "        d_x = d_out.dot(self.weights.transpose())\n",
    "        return d_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "    \n",
    "    def initialize(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w0 =  0.5\n",
    "        w1 =  0.2159198015\n",
    "        w3 = -0.0082176259\n",
    "        w5 =  0.0001825597\n",
    "        w7 = -0.0000018848\n",
    "        w9 =  0.0000000072\n",
    "        \n",
    "        x2 = x  * x\n",
    "        x3 = x2 * x\n",
    "        x5 = x2 * x3\n",
    "        x7 = x2 * x5\n",
    "        x9 = x2 * x7\n",
    "        \n",
    "        out = x9*w9 + x7*w7 + x5*w5 + x3*w3 + x*w1 + w0\n",
    "        self.cache = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, d_out):\n",
    "        out = self.cache\n",
    "        d_x = d_out * out * (out.neg() + 1)\n",
    "        return d_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential:\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def initialize(self):\n",
    "        for layer in self.layers:\n",
    "            layer.initialize()\n",
    "    \n",
    "    def forward(self, x, train=False):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, y):\n",
    "        for layer in reversed(self.layers):\n",
    "            y = layer.backward(y)\n",
    "            \n",
    "    def fit(self, x_train, y_train, loss, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(x_train)\n",
    "            dout = loss.derive(y_pred, y_train)\n",
    "            self.backward(dout)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple:\n",
    "    \n",
    "    def derive(self, y_pred, y_train):\n",
    "        return y_pred - y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(4, 2),\n",
    "    Sigmoid(),\n",
    "    Dense(1, 4),\n",
    "    Sigmoid()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrivateTensor([[ 0.01398182]\n",
       " [ 0.01002933]\n",
       " [ 0.98819944]\n",
       " [ 0.98568798]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = PrivateTensor.load(np.array([\n",
    "# x = NumpyTensor.load(np.array([\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "]))\n",
    "\n",
    "y = PrivateTensor.load(np.array([[\n",
    "# y = NumpyTensor.load(np.array([[\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1\n",
    "]]).T)\n",
    "\n",
    "model.initialize()\n",
    "\n",
    "model.fit(x, y, Simple(), epochs=10000)\n",
    "\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
