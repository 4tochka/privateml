{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from math import log\n",
    "log2 = lambda x: log(x)/log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for arbitrary precision ints\n",
    "\n",
    "DTYPE = 'object'\n",
    "Q = 503928829565480993\n",
    "\n",
    "# we need room for summing MAX_SUM values of MAX_DEGREE before during modulus reduction\n",
    "MAX_DEGREE = 2\n",
    "MAX_SUM = 2**10\n",
    "assert MAX_DEGREE * log2(Q) + log2(MAX_SUM) < 128\n",
    "\n",
    "BASE = 2\n",
    "PRECISION_INTEGRAL   = 10\n",
    "PRECISION_FRACTIONAL = 16\n",
    "# TODO Gap as needed for local truncating\n",
    "\n",
    "# we need room for double precision before truncating\n",
    "assert PRECISION_INTEGRAL + 2 * PRECISION_FRACTIONAL < log(Q)/log(BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for arbitrary precision ints\n",
    "\n",
    "DTYPE = 'object'\n",
    "Q = 2657003489534545107915232808830590043\n",
    "\n",
    "# we need room for summing MAX_SUM values of MAX_DEGREE before during modulus reduction\n",
    "MAX_DEGREE = 2\n",
    "MAX_SUM = 2**12\n",
    "assert MAX_DEGREE * log2(Q) + log2(MAX_SUM) < 256\n",
    "\n",
    "BASE = 2\n",
    "PRECISION_INTEGRAL   = 16\n",
    "PRECISION_FRACTIONAL = 32\n",
    "# TODO Gap as needed for local truncating\n",
    "\n",
    "# we need room for double precision before truncating\n",
    "assert PRECISION_INTEGRAL + 2 * PRECISION_FRACTIONAL < log(Q)/log(BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(rationals):\n",
    "    return (rationals * BASE**PRECISION_FRACTIONAL).astype('int').astype(DTYPE) % Q\n",
    "\n",
    "def decode(elements):\n",
    "    map_negative_range = np.vectorize(lambda element: element if element <= Q/2 else element - Q)\n",
    "    return map_negative_range(elements) / BASE**PRECISION_FRACTIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PublicTensor:\n",
    "    \n",
    "    def __init__(self, values):\n",
    "        self.values = values\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.values.shape\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"PublicTensor(%s)\" % decode(self.values)\n",
    "    \n",
    "    def load(values, apply_encoding=True):\n",
    "        if apply_encoding: values = encode(values)\n",
    "        return PublicTensor(values)\n",
    "    \n",
    "    def unwrap(self):\n",
    "        return self.values\n",
    "    \n",
    "    def truncate(self, amount=PRECISION_FRACTIONAL):\n",
    "        truncate = np.vectorize(lambda x: x // BASE**amount if x <= Q/2 else Q - ((Q - x) // BASE**amount))\n",
    "        return PublicTensor(truncate(self.values))\n",
    "    \n",
    "    def add(x, y):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            return PublicTensor((x.values + y.values) % Q)\n",
    "        elif isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.values + y.shares0) % Q\n",
    "            shares1 =             y.shares1\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __add__(x, y):\n",
    "        return x.add(y)\n",
    "        \n",
    "    def sub(x, y):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            return PublicTensor((x.values - y.values) % Q)\n",
    "        elif isinstance(y, PrivateTensor):\n",
    "            # TODO might be more efficient way\n",
    "            shares0 = ((Q-1) * y.shares0 + x.values) % Q\n",
    "            shares1 = ((Q-1) * y.shares1) % Q\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        elif isinstance(y, PublicTensor):\n",
    "            shares0 = (x.shares0 - y.values) % Q\n",
    "            shares1 =  x.shares1\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __sub__(x, y):\n",
    "        return x.sub(y)\n",
    "        \n",
    "    def mul(x, y, truncate=True):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            values = (x.values * y.values) % Q\n",
    "            z = PublicTensor(values)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.values * y.shares0) % Q\n",
    "            shares1 = (x.values * y.shares1) % Q\n",
    "            z = PrivateTensor(shares0, shares1)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "    \n",
    "    def __mul__(x, y):\n",
    "        return x.mul(y)\n",
    "    \n",
    "    def div(x, y):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            return PublicTensor(encode(decode(x.values) / decode(y.values)))\n",
    "        elif isinstance(y, int) or isinstance(y, float):\n",
    "            return PublicTensor(encode(decode(x.values) / y))\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return PublicTensor(encode(decode(x.values) / y))\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __div__(x, y):\n",
    "        return x.div(y)\n",
    "    \n",
    "    def dot(x, y, truncate=True):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            z = PublicTensor(x.values.dot(y.values) % Q)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, PrivateTensor):\n",
    "            shares0 = x.values.dot(y.shares0) % Q\n",
    "            shares1 = x.values.dot(y.shares1) % Q\n",
    "            z = PrivateTensor(shares0, shares1)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def transpose(x):\n",
    "        return PublicTensor(x.values.T)\n",
    "    \n",
    "    def sum0(x):\n",
    "        return PublicTensor(x.values.sum(axis=0, keepdims=True))\n",
    "    \n",
    "    def sum1(x):\n",
    "        return PublicTensor(x.values.sum(axis=1, keepdims=True))\n",
    "        \n",
    "    def exp(x):\n",
    "        return PublicTensor(encode(np.exp(decode(x.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = PublicTensor.load(np.array([1,2,3,4]).reshape(4,1) - 2); print(x)\n",
    "# y = PublicTensor.load(np.array([5,6,7,8]).reshape(4,1)); print(y)\n",
    "# z = x + y; print(z)\n",
    "# z = (x * y); print(z)\n",
    "# z = x.dot(y.transpose()); print(z)\n",
    "# z = z.sum0(); print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mul_triple(shape):\n",
    "    a = np.array([ random.randrange(Q) for _ in range(np.prod(shape)) ]).astype(DTYPE).reshape(shape)\n",
    "    b = np.array([ random.randrange(Q) for _ in range(np.prod(shape)) ]).astype(DTYPE).reshape(shape)\n",
    "    ab = (a * b) % Q\n",
    "    return PrivateTensor.load(a, False), \\\n",
    "           PrivateTensor.load(b, False), \\\n",
    "           PrivateTensor.load(ab, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dot_triple(m, n, o):\n",
    "    a = np.array([ random.randrange(Q) for _ in range(m*n) ]).astype(DTYPE).reshape((m,n))\n",
    "    b = np.array([ random.randrange(Q) for _ in range(n*o) ]).astype(DTYPE).reshape((n,o))\n",
    "    ab = np.dot(a, b)\n",
    "    return PrivateTensor.load(a, False), \\\n",
    "           PrivateTensor.load(b, False), \\\n",
    "           PrivateTensor.load(ab, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrivateTensor:\n",
    "    \n",
    "    def __init__(self, shares0, shares1):\n",
    "        self.shares0 = shares0\n",
    "        self.shares1 = shares1\n",
    "\n",
    "    def load(values, apply_encoding=True):\n",
    "        if apply_encoding: values = encode(values)\n",
    "        shares0 = np.array([ random.randrange(Q) for _ in range(values.size) ]).astype(DTYPE).reshape(values.shape)\n",
    "        shares1 = (values - shares0) % Q\n",
    "        return PrivateTensor(shares0, shares1)\n",
    "    \n",
    "    def unwrap(self):\n",
    "        return (self.shares0 + self.shares1) % Q\n",
    "    \n",
    "    def reveal(self):\n",
    "        values = (self.shares0 + self.shares1) % Q\n",
    "        return PublicTensor(values)\n",
    "    \n",
    "    def truncate(self, amount=PRECISION_FRACTIONAL):\n",
    "        shares0 = np.floor_divide(self.shares0, BASE**amount)\n",
    "        shares1 = Q - (np.floor_divide(Q - self.shares1, BASE**amount))\n",
    "        return PrivateTensor(shares0, shares1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"PrivateTensor(%s)\" % decode(self.reveal().values)\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.shares0.shape\n",
    "    \n",
    "    def add(x, y):\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.shares0 + y.shares0) % Q\n",
    "            shares1 = (x.shares1 + y.shares1) % Q\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        elif isinstance(y, PublicTensor):\n",
    "            shares0 = (x.shares0 + y.values) % Q\n",
    "            shares1 =  x.shares1\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return x.add(PublicTensor.load(y))\n",
    "        elif isinstance(y, int) or isinstance(y, float):\n",
    "            return x.add(PublicTensor.load(np.array([y])))\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __add__(x, y):\n",
    "        return x.add(y)\n",
    "    \n",
    "    def sub(x, y):\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.shares0 - y.shares0) % Q\n",
    "            shares1 = (x.shares1 - y.shares1) % Q\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        elif isinstance(y, PublicTensor):\n",
    "            shares0 = (x.shares0 - y.values) % Q\n",
    "            shares1 =  x.shares1\n",
    "            return PrivateTensor(shares0, shares1)\n",
    "        elif isinstance(y, int):\n",
    "            y = PublicTensor.load(np.array([y]))\n",
    "            return x.sub(y)\n",
    "        elif isinstance(y, float):\n",
    "            y = PublicTensor.load(np.array([y]))\n",
    "            return x.sub(y)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __sub__(x, y):\n",
    "        return x.sub(y)\n",
    "    \n",
    "    def mul(x, y, truncate=True, precomputed=None):\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            assert x.shares0.shape == x.shares1.shape == y.shares0.shape == y.shares1.shape\n",
    "            if precomputed is None: precomputed = generate_mul_triple(x.shares0.shape)\n",
    "            a, b, ab = precomputed\n",
    "            assert x.shape == a.shape\n",
    "            assert y.shape == b.shape\n",
    "            alpha = (x - a).reveal()\n",
    "            beta  = (y - b).reveal()\n",
    "            z = alpha.mul(beta, truncate=False) + \\\n",
    "                alpha.mul(b, truncate=False) + \\\n",
    "                a.mul(beta, truncate=False) + \\\n",
    "                ab\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, PublicTensor):\n",
    "            shares0 = (x.shares0 * y.values) % Q\n",
    "            shares1 = (x.shares1 * y.values) % Q\n",
    "            z = PrivateTensor(shares0, shares1)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return x.mul(PublicTensor.load(y), truncate, precomputed)\n",
    "        elif isinstance(y, int) or isinstance(y, float):\n",
    "            return x.mul(PublicTensor.load(np.array([y])), truncate, precomputed)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __mul__(x, y):\n",
    "        return x.mul(y)\n",
    "        \n",
    "    def dot(x, y, truncate=True, precomputed=None):\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            assert x.shares0.shape == x.shares1.shape \n",
    "            assert y.shares0.shape == y.shares1.shape\n",
    "            m = x.shares0.shape[0]\n",
    "            n = x.shares0.shape[1]\n",
    "            o = y.shares0.shape[1]\n",
    "            assert n == y.shares0.shape[0]\n",
    "            if precomputed is None: precomputed = generate_dot_triple(m, n, o)\n",
    "            a, b, ab = precomputed\n",
    "            alpha = (x - a).reveal()\n",
    "            beta  = (y - b).reveal()\n",
    "            z = alpha.dot(beta, truncate=False) + \\\n",
    "                alpha.dot(b, truncate=False) + \\\n",
    "                a.dot(beta, truncate=False) + \\\n",
    "                ab\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, PublicTensor):\n",
    "            shares0 = x.shares0.dot(y.values) % Q\n",
    "            shares1 = x.shares1.dot(y.values) % Q\n",
    "            z = PrivateTensor(shares0, shares1)\n",
    "            if truncate: z = z.truncate()\n",
    "            return z\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return x.dot(PublicTensor.load(y))\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def neg(self):\n",
    "        return self.mul(PublicTensor(np.array([Q - 1])), truncate=False)\n",
    "        \n",
    "    def transpose(self):\n",
    "        return PrivateTensor(self.shares0.T, self.shares1.T)\n",
    "    \n",
    "    def sum0(self):\n",
    "        shares0 = self.shares0.sum(axis=0, keepdims=True) % Q\n",
    "        shares1 = self.shares1.sum(axis=0, keepdims=True) % Q\n",
    "        return PrivateTensor(shares0, shares1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = PrivateTensor.load(np.array([1,2,3,4]).reshape(4,1) - 2)\n",
    "# y = PrivateTensor.load(np.array([5,6,7,8]).reshape(4,1))\n",
    "# z = x + y; print(z)\n",
    "# z = (x * y); print(z)\n",
    "# z = x.dot(y.transpose()); print(z)\n",
    "# z = z.sum0(); print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyTensor:\n",
    "    \n",
    "    def __init__(self, values):\n",
    "        self.values = values\n",
    "        \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.values.shape\n",
    "\n",
    "    def load(values):\n",
    "        return NumpyTensor(values)\n",
    "    \n",
    "    def unwrap(self):\n",
    "        return self.values\n",
    "\n",
    "    def reveal(self):\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"NumpyTensor(%s)\" % self.values\n",
    "    \n",
    "    def add(x, y):\n",
    "        if isinstance(y, NumpyTensor):\n",
    "            return NumpyTensor(x.values + y.values)\n",
    "        elif isinstance(y, int):\n",
    "            return NumpyTensor(x.values + y)\n",
    "        elif isinstance(y, float):\n",
    "            return NumpyTensor(x.values + y)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return NumpyTensor(x.values + y)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __add__(x, y):\n",
    "        return x.add(y)\n",
    "    \n",
    "    def sub(x, y):\n",
    "        if isinstance(y, NumpyTensor):\n",
    "            return NumpyTensor(x.values - y.values)\n",
    "        elif isinstance(y, int):\n",
    "            return NumpyTensor(x.values - y)\n",
    "        elif isinstance(y, float):\n",
    "            return NumpyTensor(x.values - y)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return NumpyTensor(x.values - y)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __sub__(x, y):\n",
    "        return x.sub(y)\n",
    "    \n",
    "    def mul(x, y):\n",
    "        if isinstance(y, NumpyTensor):\n",
    "            return NumpyTensor(x.values * y.values)\n",
    "        elif isinstance(y, int):\n",
    "            return NumpyTensor(x.values * y)\n",
    "        elif isinstance(y, float):\n",
    "            return NumpyTensor(x.values * y)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return NumpyTensor(x.values * y)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __mul__(x, y):\n",
    "        return x.mul(y)\n",
    "    \n",
    "    def div(x, y):\n",
    "        if isinstance(y, NumpyTensor):\n",
    "            return NumpyTensor(x.values / y.values)\n",
    "        elif isinstance(y, int):\n",
    "            return NumpyTensor(x.values / y)\n",
    "        elif isinstance(y, float):\n",
    "            return NumpyTensor(x.values / y)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return NumpyTensor(x.values / y)\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def __div__(x, y):\n",
    "        return x.div(y)\n",
    "        \n",
    "    def dot(x, y):\n",
    "        if isinstance(y, NumpyTensor):\n",
    "            return NumpyTensor(x.values.dot(y.values))\n",
    "        elif isinstance(y, int):\n",
    "            return NumpyTensor(x.values.dot(y))\n",
    "        elif isinstance(y, float):\n",
    "            return NumpyTensor(x.values.dot(y))\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            return NumpyTensor(x.values.dot(y))\n",
    "        else:\n",
    "            print(type(y))\n",
    "            raise Error\n",
    "        \n",
    "    def transpose(x):\n",
    "        return NumpyTensor(x.values.T)\n",
    "    \n",
    "    def neg(x):\n",
    "        return NumpyTensor(0 - x.values)\n",
    "\n",
    "    def sum0(x):\n",
    "        return NumpyTensor(x.values.sum(axis=0, keepdims=True))\n",
    "    \n",
    "    def sum1(x):\n",
    "        return NumpyTensor(x.values.sum(axis=1, keepdims=True))\n",
    "    \n",
    "    def exp(x):\n",
    "        return NumpyTensor(np.exp(x.values))\n",
    "    \n",
    "    def log(x):\n",
    "        return NumpyTensor(np.log(x.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = NumpyTensor.load(np.array([1,2,3,4]).reshape(4,1) - 2)\n",
    "# y = NumpyTensor.load(np.array([5,6,7,8]).reshape(4,1))\n",
    "# z = x + y; print(z)\n",
    "# z = (x * y); print(z)\n",
    "# z = x.dot(y.transpose()); print(z)\n",
    "# z = z.sum0(); print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
